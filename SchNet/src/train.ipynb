{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from schnet.atoms import stats_per_atom\n",
    "from schnet.models import SchNet\n",
    "from schnet.data import ASEReader, DataProvider\n",
    "from schnet.models import SchNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepares the qm9 database where energy U0 will be the target \n",
    "data_reader = ASEReader('qm9.db', # path to database\n",
    "                        ['energy_U0'], # target property\n",
    "                        [], [(None, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = 1004.55 # standard deviation of energy values for the current training data\n",
    "mean = -10560.7 # mean of energy values for the current training data\n",
    "\n",
    "class AtomGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"Dataloader for batch generation.\"\"\"\n",
    "    def __init__(self,data_reader,ids,tar='energy_U0',batch_size=16,shuffle=False):\n",
    "        self.data = data_reader\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.tar = tar\n",
    "        self.index = ids\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index)//self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ind = self.index[self.batch_size*index:self.batch_size*(index+1)]\n",
    "        return self.get_batch(ind)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.index = self.index[np.random.permutation(len(self.index))]\n",
    "    \n",
    "    def get_batch(self,idx):\n",
    "        batch = self.data[idx]\n",
    "        x_b = batch\n",
    "        x_b = {k:x[None,...] for k,x in x_b.items()}\n",
    "        y_b = (batch[self.tar][None,...]-mean)/std # for training we normalize the target values to std==1 and mean==0\n",
    "        return x_b,y_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = 'energy_U0'\n",
    "batch_size = 24\n",
    "intensive = True\n",
    "\n",
    "\n",
    "N = len(data_reader)\n",
    "\n",
    "train_idx, val_idx = train_test_split(np.arange(N),test_size=0.1,random_state=42)\n",
    "\n",
    "train_provider = AtomGenerator(data_reader, batch_size=batch_size, ids=train_idx)\n",
    "\n",
    "val_provider = AtomGenerator(data_reader, batch_size=batch_size, ids=val_idx)\n",
    "\n",
    "atomref = np.load('atomref.npz')['atom_ref']\n",
    "\n",
    "try:\n",
    "    atomref = np.load('atomref.npz')['atom_ref']\n",
    "    if tar == 'energy_U0':\n",
    "        atomref = atomref[:, 1:2]\n",
    "    if tar == 'energy_U':\n",
    "        atomref = atomref[:, 2:3]\n",
    "    if tar == 'enthalpy_H':\n",
    "        atomref = atomref[:, 3:4]\n",
    "    if tar == 'free_G':\n",
    "        atomref = atomref[:, 4:5]\n",
    "    if tar == 'Cv':\n",
    "        atomref = atomref[:, 5:6]\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "# determine statistics (std and mean) of the train data\n",
    "if 0:\n",
    "    E = data_reader.get_property(tar, train_idx)\n",
    "    Z = data_reader.get_atomic_numbers(train_idx)\n",
    "    mean_energy_per_atom, stddev_energy_per_atom = \\\n",
    "        stats_per_atom(E, Z, intensive, atomref)\n",
    "    print('Energy statistics: mu/atom=' + str(mean_energy_per_atom) +\n",
    "                 ', std/atom=' + str(stddev_energy_per_atom))\n",
    "\n",
    "\n",
    "\n",
    "schnet = SchNet(6, 64, 64, 20,\n",
    "                filter_pool_mode='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") # (action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/True, if pretrained weights shall be loaded\n",
    "weight_path = 'schnet_weights.h5'\n",
    "if 1:\n",
    "    schnet.predict(train_provider.__getitem__(1)[0]) # necessary for building the model\n",
    "    schnet.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "schnet.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(lr=1e-4),metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 5020 steps, validate for 557 steps\n",
      "Epoch 1/2\n",
      "4864/5020 [============================>.] - ETA: 9s - loss: 3.7421e-04 - mae: 0.0110"
     ]
    }
   ],
   "source": [
    "schnet.fit(x=train_provider,validation_data=val_provider,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1: #1/True if model weights shall be saved\n",
    "    schnet.save_weights('schnet_weights_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/phllipgrass/venvs/Schnetvenv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: model.tf/assets\n"
     ]
    }
   ],
   "source": [
    "if 0: #1/True if model shall be saved in tf SavedModel format\n",
    "    schnet.save('schnet',save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Schnet",
   "language": "python",
   "name": "schnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
